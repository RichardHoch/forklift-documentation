// Module included in the following assemblies:
//
// * documentation/doc-Migration_Toolkit_for_Virtualization/master.adoc

:_mod-docs-content-type: PROCEDURE
[id="migrating-live-cnv-cnv-vms-cli_{context}"]

= Performing a live migration using the {project-short} CLI

[role="_abstract"]
You can perform a live migration by using the command-line interface (CLI). The procedure for live migration is identical to the procedure for other migrations between {virt} clusters except for the addition of the `type` label in the `Plan` CR. For a live migration, the `type` label must be set to `live`.

.Prerequisites
As described in the prerequisites for live migration. For more information, see xref:cnv-cnv-live-prerequisites_mtv[{virt} live migration prerequisites].

.Procedure
. Create a `Secret` manifest for the source provider credentials:
+
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: v1
kind: Secret
metadata:
  name: <secret>
  namespace: <namespace>
  ownerReferences: <1>
    - apiVersion: forklift.konveyor.io/v1beta1
      kind: Provider
      name: <provider_name>
      uid: <provider_uid>
  labels:
    createdForProviderType: openshift
    createdForResourceType: providers
type: Opaque
stringData:
  token: <token> <2>
  password: <password> <3>
  insecureSkipVerify: <"true"/"false"> <4>
  cacert: | <5>
    <ca_certificate>
  url: <api_end_point> <6>
EOF
----
<1> The `ownerReferences` section is optional.
<2> Specify a token for a service account with `cluster-admin` privileges. If both `token` and `url` are left blank, the local {ocp-short} cluster is used.
<3> Specify the user password.
<4> Specify `"true"` to skip certificate verification, and specify `"false"` to verify the certificate. Defaults to `"false"` if not specified. Skipping certificate verification proceeds with an insecure migration and then the certificate is not required. Insecure migration means that the transferred data is sent over an insecure connection and potentially sensitive data could be exposed.
<5> When this field is not set and 'skip certificate verification' is disabled, {project-short} attempts to use the system CA.
<6> Specify the URL of the endpoint of the API server.

. Create a `Provider` manifest for the source provider:
+
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: Provider
metadata:
  name: <source_provider>
  namespace: <namespace>
spec:
  type: openshift
  url: <api_end_point> <1>
  secret:
    name: <secret> <2>
    namespace: <namespace>
EOF
----
<1> Specify the URL of the endpoint of the API server.
<2> Specify the name of provider `Secret` CR.

. Create a `NetworkMap` manifest to map the source and destination networks:
+
[source,yaml,subs="attributes+"]
----
$  cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: NetworkMap
metadata:
  name: <network_map>
  namespace: <namespace>
spec:
  map:
    - destination:
        name: <network_name>
        type: pod <1>
      source:
        name: <network_name>
        type: pod
    - destination:
        name: <network_attachment_definition> <2>
        namespace: <network_attachment_definition_namespace> <3>
        type: multus
      source:
        name: <network_attachment_definition>
        namespace: <network_attachment_definition_namespace>
        type: multus
  provider:
    source:
      name: <source_provider>
      namespace: <namespace>
    destination:
      name: <destination_provider>
      namespace: <namespace>
EOF
----
<1> Allowed values are `pod`, `ignored`, and `multus`.
<2> Specify the network name. When the `type` is `multus`, use the {virt} network attachment definition name.
<3> Required only when the `type` is `multus`. Specify the namespace of the {virt} network attachment definition. 

. Create a `StorageMap` manifest to map source and destination storage:
+
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: StorageMap
metadata:
  name: <storage_map>
  namespace: <namespace>
spec:
  map:
    - destination:
        storageClass: <storage_class>
        accessMode: <access_mode> <1>
      source:
        name: <storage_class>
  provider:
    source:
      name: <source_provider>
      namespace: <namespace>
    destination:
      name: <destination_provider>
      namespace: <namespace>
EOF
----
<1> Allowed values are `ReadWriteOnce` and `ReadWriteMany`.
+
. Optional: Create a `Hook` manifest to run custom code on a VM during the phase specified in the `Plan` CR:
+
[source,yaml,subs="attributes+"]
----
$  cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: Hook
metadata:
  name: <hook>
  namespace: <namespace>
spec:
  image: quay.io/kubev2v/hook-runner
  serviceAccount:<service account> <1>
  playbook: |
    LS0tCi0gbm... <2>
EOF
----
<1> Optional: {ocp} service account. Use the `serviceAccount` parameter to modify any cluster resources.
<2> Base64-encoded Ansible Playbook. If you specify a playbook, the `image` must include an `ansible-runner`.
+
[NOTE]
====
You can use the default `hook-runner` image or specify a custom image. If you specify a custom image, you do not have to specify a playbook.
====

. Create a `Plan` manifest for the migration:
+
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: Plan
metadata:
  name: <plan> <1>
  namespace: <namespace>
spec:
  provider:
    source:
      name: <source_provider>
      namespace: <namespace>
    destination:
      name: <destination_provider>
      namespace: <namespace>
  map: <2>
    network: <3>
      name: <network_map> <4>
      namespace: <namespace>
    storage: <5>
      name: <storage_map> <6>
      namespace: <namespace>
  type: live <7>
  targetNamespace: <target_namespace>
  vms:
    - name: <source_vm>
      namespace: <namespace>
      hooks: <8>
        - hook:
            namespace: <namespace>
            name: <hook> <9>
          step: <step> <10>
EOF
----
<1> Specify the name of the `Plan` CR.
<2> Specify only one network map and one storage map per plan.
<3> Specify a network mapping, even if the VMs to be migrated are not assigned to a network. The mapping can be empty in this case.
<4> Specify the name of the `NetworkMap` CR.
<5> Specify a storage mapping, even if the VMs to be migrated are not assigned with disk images. The mapping can be empty in this case.
<6> Specify the name of the `StorageMap` CR.
<7> Must be set to `live`.
<8> Optional: Specify up to two hooks for a VM. Each hook must run during a separate migration step.
<9> Specify the name of the `Hook` CR.
<10> Allowed values are `PreHook`, before the migration plan starts, or `PostHook`, after the migration is complete.

. Create a `Migration` manifest to run the `Plan` CR:
+
[source,yaml,subs="attributes+"]
----
$ cat << EOF | {oc} apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: Migration
metadata:
  name: <name_of_migration_cr>
  namespace: <namespace>
spec:
  plan:
    name: <name_of_plan_cr>
    namespace: <namespace>
EOF
----
+
[NOTE]
====
The `cutover` field is irrelevant for live migrations, so it is not included in the `Migration` CR of this procedure. 
====

